{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelling Change - Project\n",
    "\n",
    "## Topic: Gradient Descent\n",
    "\n",
    "> `numerical` `optimisation`\n",
    "\n",
    "Gradient descent is a general method for finding minima of functions taught is widely used in many fields.\n",
    "Write out the equations for a simple gradient descent method and code an implementation in Python.\n",
    "Locate the minima of an example function who's min you can find using the analytically (that is, as we did\n",
    "in lectures and tutorials). Investigate how the convergence is affected by:\n",
    "\n",
    "1. step size or other parameters in the algorith\n",
    "2. the initial starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report details the mathematics and computer code implementation of the _Gradient Descent_ optimisation method, and investigates the behaviour of the optimisation process when subject to variance in algorithm paramaters ('step size', iteration number) and variance in the initial starting point. \n",
    "\n",
    "It is found that TODO TODO TODO\n",
    "\n",
    "### Report Structure\n",
    "\n",
    "1. [**Introduction to the Pure-Python3 Implementation.**](#1.-Introduction-to-the-Pure-Python3-Implementation)\n",
    "2. [**Introduction to the Gradient Descent method.**](#2.-Introduction-to-the-Gradient-Descent-Method)\n",
    "3. Blah\n",
    "4. Blah\n",
    "5. [**References**](#References)\n",
    "6. [**Appendix**](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction to the Pure-Python3 Implementation\n",
    "\n",
    "To assist in the exploration and communication of the Gradient Descent optimisation technique, a 'from scratch' [pure-Python](https://stackoverflow.com/a/52461357/4885590) implementation of the gradient descent algorithm has been written and is used throughout. It is a 'standalone module', and imports no third-party code. The implementation targets usefulness in learning, not performance, but is fast enough for practical example.\n",
    "\n",
    "To reduce implementation complexity and length, not all differentiable functions are supported by the implementation. Supported functions include:\n",
    "\n",
    "- [Polynomial functions](https://en.wikipedia.org/wiki/Polynomial)\n",
    "- A limited set of trigonometric functions, to explore nonlinear functions\n",
    "\n",
    "\n",
    "The implementation is wholly contained in one Python3 module, `gradient_descent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Mapping\n",
    "\n",
    "import gradient_descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Introduction to the Gradient Descent Method\n",
    "\n",
    "Gradient Descent is an iterative optimization process that can be used effectively to find local mimina of differentiable functions, particulary when those functions are convex. When the output of a differentiable function under some set of inputs can be framed as a _cost_, the minimization of this _cost function_ becomes an optimization problem to which the Gradient Descent process can be applied.\n",
    "\n",
    "The \"Deep Neural Networks\" revolution that swept through the 2010s has its foundation in the simple single-layer neural networks first published in the 1980s, and those simple networks were optimized through gradient descent. Thus, a first lesson in understanding today's hottest technological field, Deep Neural Networks, involves going right back to the start and understanding the basic Gradient Descent optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 A Function's Gradient\n",
    "\n",
    "In order to minimise a function's value, we need to ascertain which way we should nudge its inputs to decrease the output value, and we have to be sure than a series of decreases will eventually lead to a minimum (local or global). For differentiable functions, the first-derivative of a function can be the way.\n",
    "\n",
    "For a function of a single variable, $f(x)$, the rate of change at some value $x=a$ is given by the first-derivative $f'(x)$. In the case of $f(x) = x^2 + x$, we know that:\n",
    "\n",
    "$$f'(x) = 2x + 1$$\n",
    "\n",
    "and thus at $f'(1) = 2(1) + 1 = 3$ the function is increasing in output value 'to the right' and decreasing 'to the left'. At $f'(-1) = 2(-1) + 1 = -1$ the function is decreasing in output value 'to the right' and increasing 'to the left;. In either case, we know from the first-derivative which direction to nudge $x$, until we reach $f'(1/2) = 2*(1/2) + 1 = 0$ and we've reached the critical point.\n",
    "\n",
    "\n",
    "But for a multi-variable function there are multiple ways in which to influence the output value and thus multiple dimensions along which a we could change inputs. How can we extend our understanding of the direction of function decrease beyond 'left and right' and into 3-dimensions and more? We use partial derivatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $z = f(x, y)$, then we have a multi-variable function with partial derivatives:\n",
    "    \n",
    "$$f_x(x_0, y_0) = \\lim_{h \\to 0}\\frac{f(x_0+h, y_0) - f(x_0, y_0)}{h}$$\n",
    "\n",
    "$$f_y(x_0, y_0) = \\lim_{h \\to 0}\\frac{f(x_0, y_0+h) - f(x_0, y_0)}{h}$$\n",
    "\n",
    "with each capturing the rate-of-change with respect to a single variable in our multi-variable function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the $x,y$ plane, we can imagine being at some point $(x_0,y_0)$ and nudging away from that point in the plane by the vector $\\mathbf{u} = \\langle a, b \\rangle $. \n",
    "\n",
    "Now not restricted to moving 'left and right' in the x-axis or 'up and down' the y-axis, we have a **Directional Derivative** of $f$ at $(x_0,y_0)$.\n",
    "\n",
    "$$D_uf(x_0, y_0) = \\lim_{h \\to 0}\\frac{f(x_0 + ha, y_0+hb) - f(x_0, y_0)}{h}$$\n",
    "\n",
    "More intuitively, we can consider that nudge as being of length $h$ at some angle $\\theta$ (capturing direction). Thus our $a$ and $b$ are $\\cos{\\theta}$ and $\\sin{\\theta}$ respectively, and $\\mathbf{u} = \\langle a, b \\rangle $ is a vector of length 1.\n",
    "\n",
    "In fact, any... TODO\n",
    "\n",
    "\n",
    "To prove this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function $g$ of the single variable $h$ as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "g(h) & = f(x_0 + ha, y_0+hb) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "By definition of the derivative:\n",
    "\n",
    "\\begin{align}\n",
    "g'(0) & = \\lim_{h \\to 0}\\frac{g(h) - g(0)}{h} \\\\\n",
    "& = \\lim_{h \\to 0}\\frac{f(x_0+ha, y_0+hb) - f(x_0, y_0)}{h}\\\\\n",
    "& = D_uf(x_0, y_0)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Writing $x = x_0 + ha$ and $y = y_0 + hb$ we get $g(h) = f(x, y)$ and \n",
    "\n",
    "\\begin{align}\n",
    "g'(h) & = \\frac{\\partial f}{\\partial x}\\frac{\\partial x}{\\partial h} + \\frac{\\partial f}{\\partial y}\\frac{\\partial y}{\\partial h} \\\\\n",
    "& = f_x(x, y)a + f_y(x, y)b\n",
    "& = D_uf(x_0, y_0)\n",
    "\\end{align}\n",
    "\n",
    "g(h) = f(x_0 + ha, y_0+hb) \\\\\n",
    "\n",
    "\\text{then by}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the `gradient_descent` library, we can calculate the gradient vector from a `MultiVariableFunction`. For the function:**\n",
    "\n",
    "$$f(x,y) = x^2 + y^2 - 2x - 6y + 14$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\u001b[3my\u001b[23m: 2\u001b[3my\u001b[23m¹ + -6, \u001b[3mx\u001b[23m: 2\u001b[3mx\u001b[23m¹ + -2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = gradient_descent.Variable(\"x\")\n",
    "y = gradient_descent.Variable(\"y\")\n",
    "f = gradient_descent.MultiVariableFunction(\n",
    "    variables={x, y},\n",
    "    expressions=[\n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=1, exponent=2),\n",
    "        gradient_descent.PolynomialExpression(variable=y, coefficient=1, exponent=2),\n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=-2, exponent=1),\n",
    "        gradient_descent.PolynomialExpression(variable=y, coefficient=-6, exponent=1),\n",
    "        gradient_descent.ConstantExpression(real=14.0),\n",
    "    ],\n",
    ")\n",
    "\n",
    "f.gradient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Steepest Descent\n",
    "\n",
    "Now able to determine the gradient vector of a function, capturing the rate of change along each dimension of a function, the question becomes in which 'direction' to go to 'descend' or decrease the function's value?.\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Gradient Descent - Iterating Towards the Bottom\n",
    "\n",
    "Now with a method to calculate the direction of maximum descent from a point $\\mathbf{a}$ in a function's input space, we are very close to creating the _Gradient Descent_ optimisation process.\n",
    "\n",
    "Given a differentiable multi-variable function $f(\\mathbf{x})$, with $\\mathbf{x}$ being a vector of inputs $\\langle x, y, z, ... \\rangle$, then we know:\n",
    "\n",
    "**At some point $\\mathbf{a} \\in \\mathbf{x}$, $f(\\mathbf{x})$ decreases _fastest_ in the direction of the negative gradient:** $-\\nabla \\mathbf{f(a)}$\n",
    "\n",
    "In the Python library `gradient_descent`, we can calculate this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient: {\u001b[3my\u001b[23m: 2\u001b[3my\u001b[23m¹ + -6, \u001b[3mx\u001b[23m: 2\u001b[3mx\u001b[23m¹ + -2}\n",
      "Gradient of f(x, y) @ point 'a'\n",
      "{\u001b[3my\u001b[23m: -4, \u001b[3mx\u001b[23m: -4}\n"
     ]
    }
   ],
   "source": [
    "f_grad = f.gradient()\n",
    "\n",
    "print(f\"Gradient: {f_grad}\")\n",
    "\n",
    "a: gradient_descent.Point = {\n",
    "    x: -1,\n",
    "    y: 1,\n",
    "}\n",
    "\n",
    "f_grad_a: Mapping[gradient_descent.Variable, float] = {\n",
    "    var: grad_elem.evaluate(a)\n",
    "    for var, grad_elem\n",
    "    in f_grad.items()\n",
    "}\n",
    "    \n",
    "print(\"Gradient of f(x, y) @ point 'a'\")\n",
    "print(f_grad_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4  Analytical vs. Iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, understanding the process, we are ready to run Gradient Descent in Python. The optimisation problem we'll solve is minimising:\n",
    "\n",
    "$$cost= f(x,y) = x^2 + y^2 - 2x - 6y + 14$$\n",
    "\n",
    "We can solve this analytically, which will be useful in validating the Python implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "f_x(x, y) & = 2x + 0 - 2 - 0 + 0 \\\\\n",
    "f_x(x, y) & = 2x - 2\\\\\n",
    "\\\\\n",
    "f_y(x, y) & = 0 + 2y - 0 - 6 + 0 \\\\\n",
    "f_y(x, y) & = 2y - 6\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Solving...\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_x(x, y) & = 2x - 2 = 0 \\\\\n",
    "2x - 2 & = 0 \\\\\n",
    "2x & = 2 \\\\\n",
    "x & = 1 \\\\\n",
    "\\\\\n",
    "f_y(x, y) & = 2y - 6 = 0 \\\\\n",
    "2y - 6 & = 0 \\\\\n",
    "2y & = 6 \\\\\n",
    "y & = 3 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "So $f(x, y)$ has a critical point at $(1, 3)$ and we can show graphically that this critical point is a minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TODO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2494f9b4f745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TODO' is not defined"
     ]
    }
   ],
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's solve the same problem using the Python implementation of the Gradient Descent algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0. Current min estimate: {\u001b[3my\u001b[23m: 1.4, \u001b[3mx\u001b[23m: 0.2}\n",
      "Iteration 100. Current min estimate: {\u001b[3my\u001b[23m: 2.999999999674074, \u001b[3mx\u001b[23m: 0.9999999998370371}\n",
      "Iteration as not changed value. Stopping early.\n",
      "\n",
      "Results:\n",
      "Min Value: 4.000000000000002\n",
      "Min Location: {\u001b[3my\u001b[23m: 2.999999999999999, \u001b[3mx\u001b[23m: 0.9999999999999998}\n"
     ]
    }
   ],
   "source": [
    "minimum_val, minimum_point = gradient_descent.gradient_descent(\n",
    "        gamma=0.1,\n",
    "        max_iterations=5000,\n",
    "        f=f,\n",
    "    )\n",
    "print(\"\\nResults:\")\n",
    "print(f\"Min Value: {minimum_val}\")\n",
    "print(f\"Min Location: {minimum_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! The answers are not exact because of [floating-point arithmetic error](https://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html), but $(1, 3)$ is correct.\n",
    "\n",
    "We can re-run the function and no matter which values are randomly assigned to the initial starting point, the process converges to the correct result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Convergence Behaviour\n",
    "\n",
    "Having demonstrated gradient descent convergence of a simple convex function, let's investigate convergence behaviour\n",
    "on different functions when the parameters of the convergence process are manipulated.\n",
    "\n",
    "#### 3.1 Changing Max Iterations\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Changing Step Size\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Contours of f(x,y)')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "delta = 0.001\n",
    "x = np.arange(-3.0, 3.0, delta)\n",
    "y = np.arange(-2.0, 2.0, delta)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z1 = np.exp(-X**2 - Y**2)\n",
    "Z2 = np.exp(-(X - 1)**2 - (Y - 1)**2)\n",
    "Z = (Z1 - Z2) * 2\n",
    "\n",
    "x = np.linspace(-2,2)\n",
    "y = np.linspace(-2,2)\n",
    "\n",
    "# Create our grid of points\n",
    "xv, yv = np.meshgrid(x,y)\n",
    "ax = plt.subplot(1,2,1)\n",
    "\n",
    "x_extrema = np.array([-1,1])\n",
    "y_extrema = np.array([-1,1])\n",
    "z_extrema = (x_extrema**2)+(y_extrema**2) \n",
    "\n",
    "# Make a contour plot that is filled with color.\n",
    "ax.contourf(xv,yv, (1 - xv)**2+ 100*(yv - (xv**2))**2)\n",
    "ax.scatter(x_extrema, y_extrema, z_extrema,  color='r')\n",
    "ax.set_title('Contours of f(x,y)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x,y)=(1-x)^2+100(y-x^2)^2$$\n",
    "\n",
    "alternate form\n",
    "\n",
    "$$100 x^4 - 200 x^2 y + x^2 - 2 x + 100 y^2 + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration as not changed value. Stopping early.\n",
      "\n",
      "Results:\n",
      "--- Min Value: 0.0\n",
      "--- Min Location: {\u001b[3mx\u001b[23m: 1.0, \u001b[3my\u001b[23m: 1.0}\n",
      "Iteration 0. Current min estimate: {\u001b[3mx\u001b[23m: 1.0514, \u001b[3my\u001b[23m: 1.122}\n",
      "Iteration 100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0556501340690305, \u001b[3my\u001b[23m: 1.1146125607732753}\n",
      "Iteration 200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0536471191079249, \u001b[3my\u001b[23m: 1.1103801057733933}\n",
      "Iteration 300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0517104134672977, \u001b[3my\u001b[23m: 1.1062953777748823}\n",
      "Iteration 400. Current min estimate: {\u001b[3mx\u001b[23m: 1.04983821146934, \u001b[3my\u001b[23m: 1.1023538098346337}\n",
      "Iteration 500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0480287309216627, \u001b[3my\u001b[23m: 1.0985509366929211}\n",
      "Iteration 600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0462802145917032, \u001b[3my\u001b[23m: 1.09488239516209}\n",
      "Iteration 700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0445909315429642, \u001b[3my\u001b[23m: 1.0913439243029828}\n",
      "Iteration 800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0429591783371308, \u001b[3my\u001b[23m: 1.0879313654013567}\n",
      "Iteration 900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0413832801064518, \u001b[3my\u001b[23m: 1.0846406617565105}\n",
      "Iteration 1000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0398615915010792, \u001b[3my\u001b[23m: 1.0814678582942419}\n",
      "Iteration 1100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0383924975163128, \u001b[3my\u001b[23m: 1.0784091010161343}\n",
      "Iteration 1200. Current min estimate: {\u001b[3mx\u001b[23m: 1.03697441420487, \u001b[3my\u001b[23m: 1.0754606362969283}\n",
      "Iteration 1300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0356057892794677, \u001b[3my\u001b[23m: 1.072618810041523}\n",
      "Iteration 1400. Current min estimate: {\u001b[3mx\u001b[23m: 1.03428510261109, \u001b[3my\u001b[23m: 1.0698800667128283}\n",
      "Iteration 1500. Current min estimate: {\u001b[3mx\u001b[23m: 1.033010866628371, \u001b[3my\u001b[23m: 1.0672409482413752}\n",
      "Iteration 1600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0317816266235602, \u001b[3my\u001b[23m: 1.064698092827243}\n",
      "Iteration 1700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0305959609705018, \u001b[3my\u001b[23m: 1.0622482336444663}\n",
      "Iteration 1800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0294524812600376, \u001b[3my\u001b[23m: 1.059888197457701}\n",
      "Iteration 1900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0283498323581453, \u001b[3my\u001b[23m: 1.0576149031604813}\n",
      "Iteration 2000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0272866923920594, \u001b[3my\u001b[23m: 1.0554253602440251}\n",
      "Iteration 2100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0262617726694783, \u001b[3my\u001b[23m: 1.0533166672050618}\n",
      "Iteration 2200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0252738175358422, \u001b[3my\u001b[23m: 1.0512860099007526}\n",
      "Iteration 2300. Current min estimate: {\u001b[3mx\u001b[23m: 1.024321604174514, \u001b[3my\u001b[23m: 1.0493306598583225}\n",
      "Iteration 2400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0234039423545296, \u001b[3my\u001b[23m: 1.0474479725465962}\n",
      "Iteration 2500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0225196741304146, \u001b[3my\u001b[23m: 1.0456353856161866}\n",
      "Iteration 2600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0216676734983858, \u001b[3my\u001b[23m: 1.043890417114684}\n",
      "Iteration 2700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0208468460130695, \u001b[3my\u001b[23m: 1.042210663682768}\n",
      "Iteration 2800. Current min estimate: {\u001b[3mx\u001b[23m: 1.020056128368674, \u001b[3my\u001b[23m: 1.0405937987367482}\n",
      "Iteration 2900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0192944879483672, \u001b[3my\u001b[23m: 1.039037570642671}\n",
      "Iteration 3000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0185609223454168, \u001b[3my\u001b[23m: 1.0375398008867405}\n",
      "Iteration 3100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0178544588594571, \u001b[3my\u001b[23m: 1.0360983822464305}\n",
      "Iteration 3200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0171741539710502, \u001b[3my\u001b[23m: 1.034711276966321}\n",
      "Iteration 3300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0165190927975334, \u001b[3my\u001b[23m: 1.0333765149423486}\n",
      "Iteration 3400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0158883885329484, \u001b[3my\u001b[23m: 1.0320921919178505}\n",
      "Iteration 3500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0152811818746745, \u001b[3my\u001b[23m: 1.0308564676944634}\n",
      "Iteration 3600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0146966404392104, \u001b[3my\u001b[23m: 1.0296675643606479}\n",
      "Iteration 3700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0141339581693802, \u001b[3my\u001b[23m: 1.0285237645403527}\n",
      "Iteration 3800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0135923547350703, \u001b[3my\u001b[23m: 1.0274234096640311}\n",
      "Iteration 3900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0130710749294634, \u001b[3my\u001b[23m: 1.0263648982640412}\n",
      "Iteration 4000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0125693880625537, \u001b[3my\u001b[23m: 1.0253466842961514}\n",
      "Iteration 4100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0120865873536187, \u001b[3my\u001b[23m: 1.0243672754887296}\n",
      "Iteration 4200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0116219893241558, \u001b[3my\u001b[23m: 1.0234252317209458}\n",
      "Iteration 4300. Current min estimate: {\u001b[3mx\u001b[23m: 1.011174933192678, \u001b[3my\u001b[23m: 1.0225191634311437}\n",
      "Iteration 4400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0107447802726275, \u001b[3my\u001b[23m: 1.0216477300563576}\n",
      "Iteration 4500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0103309133745622, \u001b[3my\u001b[23m: 1.0208096385038037}\n",
      "Iteration 4600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0099327362136439, \u001b[3my\u001b[23m: 1.020003641654994}\n",
      "Iteration 4700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0095496728233577, \u001b[3my\u001b[23m: 1.0192285369030036}\n",
      "Iteration 4800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0091811669763013, \u001b[3my\u001b[23m: 1.0184831647232884}\n",
      "Iteration 4900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0088266816127776, \u001b[3my\u001b[23m: 1.0177664072783241}\n",
      "Iteration 5000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0084856982778476, \u001b[3my\u001b[23m: 1.017077187056238}\n",
      "Iteration 5100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0081577165674174, \u001b[3my\u001b[23m: 1.0164144655435035}\n",
      "Iteration 5200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0078422535838556, \u001b[3my\u001b[23m: 1.0157772419316689}\n",
      "Iteration 5300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0075388434015677, \u001b[3my\u001b[23m: 1.0151645518580186}\n",
      "Iteration 5400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0072470365428952, \u001b[3my\u001b[23m: 1.0145754661799855}\n",
      "Iteration 5500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0069663994646456, \u001b[3my\u001b[23m: 1.0140090897830838}\n",
      "Iteration 5600. Current min estimate: {\u001b[3mx\u001b[23m: 1.006696514055489, \u001b[3my\u001b[23m: 1.0134645604220192}\n",
      "Iteration 5700. Current min estimate: {\u001b[3mx\u001b[23m: 1.006436977144438, \u001b[3my\u001b[23m: 1.0129410475946614}\n",
      "Iteration 5800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0061874000205455, \u001b[3my\u001b[23m: 1.0124377514484344}\n",
      "Iteration 5900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0059474079639374, \u001b[3my\u001b[23m: 1.011953901718691}\n",
      "Iteration 6000. Current min estimate: {\u001b[3mx\u001b[23m: 1.005716639788249, \u001b[3my\u001b[23m: 1.0114887566985795}\n",
      "Iteration 6100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0054947473944933, \u001b[3my\u001b[23m: 1.0110416022398852}\n",
      "Iteration 6200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0052813953363713, \u001b[3my\u001b[23m: 1.0106117507842953}\n",
      "Iteration 6300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0050762603969867, \u001b[3my\u001b[23m: 1.0101985404245153}\n",
      "Iteration 6400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0048790311769178, \u001b[3my\u001b[23m: 1.0098013339946514}\n",
      "Iteration 6500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0046894076935602, \u001b[3my\u001b[23m: 1.0094195181892371}\n",
      "Iteration 6600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0045071009916524, \u001b[3my\u001b[23m: 1.009052502710302}\n",
      "Iteration 6700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0043318327648516, \u001b[3my\u001b[23m: 1.008699719441832}\n",
      "Iteration 6800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0041633349882368, \u001b[3my\u001b[23m: 1.008360621650997}\n",
      "Iteration 6900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0040013495615765, \u001b[3my\u001b[23m: 1.008034683215485}\n",
      "Iteration 7000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0038456279632093, \u001b[3my\u001b[23m: 1.0077213978763102}\n",
      "Iteration 7100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0036959309143538, \u001b[3my\u001b[23m: 1.0074202785154385}\n",
      "Iteration 7200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0035520280536678, \u001b[3my\u001b[23m: 1.0071308564575792}\n",
      "Iteration 7300. Current min estimate: {\u001b[3mx\u001b[23m: 1.003413697621864, \u001b[3my\u001b[23m: 1.0068526807955114}\n",
      "Iteration 7400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0032807261561743, \u001b[3my\u001b[23m: 1.0065853177382755}\n",
      "Iteration 7500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0031529081944766, \u001b[3my\u001b[23m: 1.0063283499816325}\n",
      "Iteration 7600. Current min estimate: {\u001b[3mx\u001b[23m: 1.00303004598885, \u001b[3my\u001b[23m: 1.0060813761001217}\n",
      "Iteration 7700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0029119492283602, \u001b[3my\u001b[23m: 1.005844009960118}\n",
      "Iteration 7800. Current min estimate: {\u001b[3mx\u001b[23m: 1.002798434770857, \u001b[3my\u001b[23m: 1.0056158801532682}\n",
      "Iteration 7900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0026893263835615, \u001b[3my\u001b[23m: 1.0053966294496977}\n",
      "Iteration 8000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0025844544922247, \u001b[3my\u001b[23m: 1.0051859142703934}\n",
      "Iteration 8100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0024836559386434, \u001b[3my\u001b[23m: 1.0049834041781824}\n",
      "Iteration 8200. Current min estimate: {\u001b[3mx\u001b[23m: 1.002386773746305, \u001b[3my\u001b[23m: 1.0047887813867191}\n",
      "Iteration 8300. Current min estimate: {\u001b[3mx\u001b[23m: 1.002293656893952, \u001b[3my\u001b[23m: 1.0046017402869352}\n",
      "Iteration 8400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0022041600968443, \u001b[3my\u001b[23m: 1.004421986990388}\n",
      "Iteration 8500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0021181435955009, \u001b[3my\u001b[23m: 1.0042492388889663}\n",
      "Iteration 8600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0020354729517194, \u001b[3my\u001b[23m: 1.0040832242304403}\n",
      "Iteration 8700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0019560188516472, \u001b[3my\u001b[23m: 1.0039236817093231}\n",
      "Iteration 8800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0018796569157102, \u001b[3my\u001b[23m: 1.0037703600725552}\n",
      "Iteration 8900. Current min estimate: {\u001b[3mx\u001b[23m: 1.001806267515188, \u001b[3my\u001b[23m: 1.0036230177395125}\n",
      "Iteration 9000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0017357355952343, \u001b[3my\u001b[23m: 1.0034814224358668}\n",
      "Iteration 9100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0016679505041468, \u001b[3my\u001b[23m: 1.0033453508408257}\n",
      "Iteration 9200. Current min estimate: {\u001b[3mx\u001b[23m: 1.001602805828693, \u001b[3my\u001b[23m: 1.0032145882473114}\n",
      "Iteration 9300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0015401992352964, \u001b[3my\u001b[23m: 1.0030889282346178}\n",
      "Iteration 9400. Current min estimate: {\u001b[3mx\u001b[23m: 1.001480032316911, \u001b[3my\u001b[23m: 1.0029681723531552}\n",
      "Iteration 9500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0014222104453816, \u001b[3my\u001b[23m: 1.0028521298208157}\n",
      "Iteration 9600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0013666426291286, \u001b[3my\u001b[23m: 1.0027406172305968}\n",
      "Iteration 9700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0013132413759773, \u001b[3my\u001b[23m: 1.00263345826908}\n",
      "Iteration 9800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0012619225609674, \u001b[3my\u001b[23m: 1.0025304834453792}\n",
      "Iteration 9900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0012126052989623, \u001b[3my\u001b[23m: 1.0024315298301858}\n",
      "Iteration 10000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0011652118219196, \u001b[3my\u001b[23m: 1.0023364408045738}\n",
      "Iteration 10100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0011196673606473, \u001b[3my\u001b[23m: 1.0022450658181927}\n",
      "Iteration 10200. Current min estimate: {\u001b[3mx\u001b[23m: 1.001075900030908, \u001b[3my\u001b[23m: 1.0021572601565416}\n",
      "Iteration 10300. Current min estimate: {\u001b[3mx\u001b[23m: 1.001033840723705, \u001b[3my\u001b[23m: 1.002072884716966}\n",
      "Iteration 10400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0009934229996276, \u001b[3my\u001b[23m: 1.0019918057930952}\n",
      "Iteration 10500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0009545829871, \u001b[3my\u001b[23m: 1.0019138948674005}\n",
      "Iteration 10600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0009172592844036, \u001b[3my\u001b[23m: 1.0018390284115775}\n",
      "Iteration 10700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0008813928653408, \u001b[3my\u001b[23m: 1.0017670876944798}\n",
      "Iteration 10800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0008469269884122, \u001b[3my\u001b[23m: 1.0016979585973167}\n",
      "Iteration 10900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000813807109381, \u001b[3my\u001b[23m: 1.0016315314358566}\n",
      "Iteration 11000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0007819807971143, \u001b[3my\u001b[23m: 1.0015677007893853}\n",
      "Iteration 11100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0007513976525668, \u001b[3my\u001b[23m: 1.0015063653361538}\n",
      "Iteration 11200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0007220092308107, \u001b[3my\u001b[23m: 1.0014474276950887}\n",
      "Iteration 11300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0006937689659983, \u001b[3my\u001b[23m: 1.0013907942735398}\n",
      "Iteration 11400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0006666320991475, \u001b[3my\u001b[23m: 1.0013363751208226}\n",
      "Iteration 11500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0006405556086502, \u001b[3my\u001b[23m: 1.0012840837873576}\n",
      "Iteration 11600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0006154981434088, \u001b[3my\u001b[23m: 1.00123383718919}\n",
      "Iteration 11700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0005914199585009, \u001b[3my\u001b[23m: 1.0011855554776947}\n",
      "Iteration 11800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000568282853278, \u001b[3my\u001b[23m: 1.0011391619142622}\n",
      "Iteration 11900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0005460501118184, \u001b[3my\u001b[23m: 1.0010945827497943}\n",
      "Iteration 12000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0005246864456336, \u001b[3my\u001b[23m: 1.0010517471088132}\n",
      "Iteration 12100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0005041579385632, \u001b[3my\u001b[23m: 1.0010105868780292}\n",
      "Iteration 12200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000484431993758, \u001b[3my\u001b[23m: 1.0009710365991782}\n",
      "Iteration 12300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0004654772826906, \u001b[3my\u001b[23m: 1.0009330333659858}\n",
      "Iteration 12400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0004472636961093, \u001b[3my\u001b[23m: 1.0008965167250934}\n",
      "Iteration 12500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000429762296863, \u001b[3my\u001b[23m: 1.000861428580795}\n",
      "Iteration 12600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0004129452745363, \u001b[3my\u001b[23m: 1.0008277131034535}\n",
      "Iteration 12700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000396785901812, \u001b[3my\u001b[23m: 1.0007953166414345}\n",
      "Iteration 12800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0003812584925118, \u001b[3my\u001b[23m: 1.0007641876364457}\n",
      "Iteration 12900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0003663383612442, \u001b[3my\u001b[23m: 1.0007342765421454}\n",
      "Iteration 13000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0003520017845975, \u001b[3my\u001b[23m: 1.000705535745882}\n",
      "Iteration 13100. Current min estimate: {\u001b[3mx\u001b[23m: 1.000338225963827, \u001b[3my\u001b[23m: 1.000677919493475}\n",
      "Iteration 13200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000324988988976, \u001b[3my\u001b[23m: 1.0006513838168904}\n",
      "Iteration 13300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0003122698043732, \u001b[3my\u001b[23m: 1.000625886464716}\n",
      "Iteration 13400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0003000481754603, \u001b[3my\u001b[23m: 1.0006013868353325}\n",
      "Iteration 13500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002883046568993, \u001b[3my\u001b[23m: 1.000577845912667}\n",
      "Iteration 13600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002770205619056, \u001b[3my\u001b[23m: 1.000555226204437}\n",
      "Iteration 13700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002661779327642, \u001b[3my\u001b[23m: 1.0005334916827864}\n",
      "Iteration 13800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002557595124844, \u001b[3my\u001b[23m: 1.000512607727221}\n",
      "Iteration 13900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002457487175511, \u001b[3my\u001b[23m: 1.0004925410697647}\n",
      "Iteration 14000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002361296117233, \u001b[3my\u001b[23m: 1.0004732597422317}\n",
      "Iteration 14100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002268868808504, \u001b[3my\u001b[23m: 1.0004547330255558}\n",
      "Iteration 14200. Current min estimate: {\u001b[3mx\u001b[23m: 1.00021800580866, \u001b[3my\u001b[23m: 1.0004369314010797}\n",
      "Iteration 14300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002094722534824, \u001b[3my\u001b[23m: 1.0004198265037392}\n",
      "Iteration 14400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0002012726258778, \u001b[3my\u001b[23m: 1.0004033910770678}\n",
      "Iteration 14500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001933938671288, \u001b[3my\u001b[23m: 1.000387598929946}\n",
      "Iteration 14600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000185823428564, \u001b[3my\u001b[23m: 1.0003724248950334}\n",
      "Iteration 14700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001785492516875, \u001b[3my\u001b[23m: 1.0003578447888162}\n",
      "Iteration 14800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001715597490755, \u001b[3my\u001b[23m: 1.0003438353732141}\n",
      "Iteration 14900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000164843786015, \u001b[3my\u001b[23m: 1.0003303743186727}\n",
      "Iteration 15000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001583906628557, \u001b[3my\u001b[23m: 1.000317440168698}\n",
      "Iteration 15100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001521900980457, \u001b[3my\u001b[23m: 1.0003050123057688}\n",
      "Iteration 15200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001462322118249, \u001b[3my\u001b[23m: 1.0002930709185751}\n",
      "Iteration 15300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001405075105567, \u001b[3my\u001b[23m: 1.0002815969705368}\n",
      "Iteration 15400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000135006871663, \u001b[3my\u001b[23m: 1.0002705721695462}\n",
      "Iteration 15500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001297215291478, \u001b[3my\u001b[23m: 1.0002599789388869}\n",
      "Iteration 15600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001246430596817, \u001b[3my\u001b[23m: 1.0002498003892875}\n",
      "Iteration 15700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001197633692305, \u001b[3my\u001b[23m: 1.0002400202920683}\n",
      "Iteration 15800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001150746802014, \u001b[3my\u001b[23m: 1.0002306230533289}\n",
      "Iteration 15900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001105695190893, \u001b[3my\u001b[23m: 1.000221593689144}\n",
      "Iteration 16000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001062407046057, \u001b[3my\u001b[23m: 1.0002129178017292}\n",
      "Iteration 16100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0001020813362698, \u001b[3my\u001b[23m: 1.0002045815565344}\n",
      "Iteration 16200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000980847834406, \u001b[3my\u001b[23m: 1.0001965716602288}\n",
      "Iteration 16300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000942446747791, \u001b[3my\u001b[23m: 1.0001888753395463}\n",
      "Iteration 16400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000090554888123, \u001b[3my\u001b[23m: 1.000181480320961}\n",
      "Iteration 16500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000870095407488, \u001b[3my\u001b[23m: 1.0001743748111458}\n",
      "Iteration 16600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000083602980021, \u001b[3my\u001b[23m: 1.0001675474782001}\n",
      "Iteration 16700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000080329774402, \u001b[3my\u001b[23m: 1.000160987433615}\n",
      "Iteration 16800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000771847048133, \u001b[3my\u001b[23m: 1.0001546842149316}\n",
      "Iteration 16900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000741627563323, \u001b[3my\u001b[23m: 1.0001486277690828}\n",
      "Iteration 17000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000071259110215, \u001b[3my\u001b[23m: 1.0001428084363864}\n",
      "Iteration 17100. Current min estimate: {\u001b[3mx\u001b[23m: 1.000068469136229, \u001b[3my\u001b[23m: 1.00013721693516}\n",
      "Iteration 17200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000657883852846, \u001b[3my\u001b[23m: 1.0001318443469387}\n",
      "Iteration 17300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000063212582354, \u001b[3my\u001b[23m: 1.0001266821022685}\n",
      "Iteration 17400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000607376196704, \u001b[3my\u001b[23m: 1.0001217219670613}\n",
      "Iteration 17500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000583595501833, \u001b[3my\u001b[23m: 1.0001169560294694}\n",
      "Iteration 17600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000056074581281, \u001b[3my\u001b[23m: 1.0001123766872886}\n",
      "Iteration 17700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000538790687477, \u001b[3my\u001b[23m: 1.0001079766358396}\n",
      "Iteration 17800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000051769510965, \u001b[3my\u001b[23m: 1.0001037488563365}\n",
      "Iteration 17900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000497425433326, \u001b[3my\u001b[23m: 1.0000996866046954}\n",
      "Iteration 18000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000477949329125, \u001b[3my\u001b[23m: 1.0000957834007935}\n",
      "Iteration 18100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000459235732784, \u001b[3my\u001b[23m: 1.0000920330181373}\n",
      "Iteration 18200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000044125479571, \u001b[3my\u001b[23m: 1.0000884294739476}\n",
      "Iteration 18300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000042397783739, \u001b[3my\u001b[23m: 1.0000849670196126}\n",
      "Iteration 18400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000407377299734, \u001b[3my\u001b[23m: 1.0000816401315367}\n",
      "Iteration 18500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000039142670317, \u001b[3my\u001b[23m: 1.0000784435023287}\n",
      "Iteration 18600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000376100604442, \u001b[3my\u001b[23m: 1.000075372032346}\n",
      "Iteration 18700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000361374556095, \u001b[3my\u001b[23m: 1.0000724208215643}\n",
      "Iteration 18800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000347225067499, \u001b[3my\u001b[23m: 1.0000695851617663}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 18900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000333629567424, \u001b[3my\u001b[23m: 1.0000668605290362}\n",
      "Iteration 19000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000320566368077, \u001b[3my\u001b[23m: 1.0000642425765458}\n",
      "Iteration 19100. Current min estimate: {\u001b[3mx\u001b[23m: 1.000030801463053, \u001b[3my\u001b[23m: 1.0000617271276278}\n",
      "Iteration 19200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000295954331524, \u001b[3my\u001b[23m: 1.0000593101691146}\n",
      "Iteration 19300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000284366231527, \u001b[3my\u001b[23m: 1.000056987844937}\n",
      "Iteration 19400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000273231844101, \u001b[3my\u001b[23m: 1.0000547564499818}\n",
      "Iteration 19500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000026253340641, \u001b[3my\u001b[23m: 1.0000526124241782}\n",
      "Iteration 19600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000252253850925, \u001b[3my\u001b[23m: 1.0000505523468257}\n",
      "Iteration 19700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000242376778194, \u001b[3my\u001b[23m: 1.0000485729311346}\n",
      "Iteration 19800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000232886430722, \u001b[3my\u001b[23m: 1.0000466710189893}\n",
      "Iteration 19900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000223767667842, \u001b[3my\u001b[23m: 1.0000448435759097}\n",
      "Iteration 20000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000215005941566, \u001b[3my\u001b[23m: 1.0000430876862123}\n",
      "Iteration 20100. Current min estimate: {\u001b[3mx\u001b[23m: 1.00002065872734, \u001b[3my\u001b[23m: 1.0000414005483589}\n",
      "Iteration 20200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000019849823206, \u001b[3my\u001b[23m: 1.0000397794704934}\n",
      "Iteration 20300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000190725912055, \u001b[3my\u001b[23m: 1.0000382218661432}\n",
      "Iteration 20400. Current min estimate: {\u001b[3mx\u001b[23m: 1.00001832579131, \u001b[3my\u001b[23m: 1.0000367252500975}\n",
      "Iteration 20500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000176082320336, \u001b[3my\u001b[23m: 1.0000352872344378}\n",
      "Iteration 20600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000169187685375, \u001b[3my\u001b[23m: 1.0000339055247427}\n",
      "Iteration 20700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000162563007995, \u001b[3my\u001b[23m: 1.000032577916412}\n",
      "Iteration 20800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000156197718604, \u001b[3my\u001b[23m: 1.00003130229116}\n",
      "Iteration 20900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000150081661432, \u001b[3my\u001b[23m: 1.000030076613638}\n",
      "Iteration 21000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000144205078263, \u001b[3my\u001b[23m: 1.0000288989281794}\n",
      "Iteration 21100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000138558592926, \u001b[3my\u001b[23m: 1.0000277673556879}\n",
      "Iteration 21200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000133133196327, \u001b[3my\u001b[23m: 1.0000266800906377}\n",
      "Iteration 21300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000127920232078, \u001b[3my\u001b[23m: 1.000025635398193}\n",
      "Iteration 21400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000122911382676, \u001b[3my\u001b[23m: 1.0000246316114387}\n",
      "Iteration 21500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000118098656268, \u001b[3my\u001b[23m: 1.0000236671287261}\n",
      "Iteration 21600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000113474373884, \u001b[3my\u001b[23m: 1.000022740411115}\n",
      "Iteration 21700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000109031157196, \u001b[3my\u001b[23m: 1.0000218499799178}\n",
      "Iteration 21800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000104761916737, \u001b[3my\u001b[23m: 1.0000209944143426}\n",
      "Iteration 21900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000100659840616, \u001b[3my\u001b[23m: 1.0000201723492257}\n",
      "Iteration 22000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000096718383629, \u001b[3my\u001b[23m: 1.0000193824728547}\n",
      "Iteration 22100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000092931256839, \u001b[3my\u001b[23m: 1.000018623524876}\n",
      "Iteration 22200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000008929241752, \u001b[3my\u001b[23m: 1.0000178942942801}\n",
      "Iteration 22300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000008579605954, \u001b[3my\u001b[23m: 1.0000171936174749}\n",
      "Iteration 22400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000082436604094, \u001b[3my\u001b[23m: 1.0000165203764289}\n",
      "Iteration 22500. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000792086908, \u001b[3my\u001b[23m: 1.0000158734968831}\n",
      "Iteration 22600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000007610716914, \u001b[3my\u001b[23m: 1.000015251946642}\n",
      "Iteration 22700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000007312709027, \u001b[3my\u001b[23m: 1.0000146547339235}\n",
      "Iteration 22800. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000702636991, \u001b[3my\u001b[23m: 1.0000140809057794}\n",
      "Iteration 22900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000067512426714, \u001b[3my\u001b[23m: 1.000013529546572}\n",
      "Iteration 23000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000064868883085, \u001b[3my\u001b[23m: 1.0000129997765155}\n",
      "Iteration 23100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000062328850081, \u001b[3my\u001b[23m: 1.0000124907502723}\n",
      "Iteration 23200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000059888274722, \u001b[3my\u001b[23m: 1.0000120016556042}\n",
      "Iteration 23300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000057543262701, \u001b[3my\u001b[23m: 1.0000115317120741}\n",
      "Iteration 23400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000055290072212, \u001b[3my\u001b[23m: 1.0000110801698032}\n",
      "Iteration 23500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000053125107935, \u001b[3my\u001b[23m: 1.0000106463082747}\n",
      "Iteration 23600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000051044915337, \u001b[3my\u001b[23m: 1.000010229435184}\n",
      "Iteration 23700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000049046175132, \u001b[3my\u001b[23m: 1.0000098288853319}\n",
      "Iteration 23800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000004712569801, \u001b[3my\u001b[23m: 1.000009444019567}\n",
      "Iteration 23900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000045280419525, \u001b[3my\u001b[23m: 1.0000090742237628}\n",
      "Iteration 24000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000043507395229, \u001b[3my\u001b[23m: 1.0000087189078397}\n",
      "Iteration 24100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000041803795958, \u001b[3my\u001b[23m: 1.000008377504824}\n",
      "Iteration 24200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000040166903317, \u001b[3my\u001b[23m: 1.0000080494699384}\n",
      "Iteration 24300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000038594105358, \u001b[3my\u001b[23m: 1.0000077342797407}\n",
      "Iteration 24400. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000370828924, \u001b[3my\u001b[23m: 1.0000074314312812}\n",
      "Iteration 24500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000035630853026, \u001b[3my\u001b[23m: 1.0000071404413056}\n",
      "Iteration 24600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000034235670245, \u001b[3my\u001b[23m: 1.0000068608454808}\n",
      "Iteration 24700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000032895117779, \u001b[3my\u001b[23m: 1.0000065921976544}\n",
      "Iteration 24800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000031607056523, \u001b[3my\u001b[23m: 1.0000063340691445}\n",
      "Iteration 24900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000030369431132, \u001b[3my\u001b[23m: 1.000006086048053}\n",
      "Iteration 25000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000029180266738, \u001b[3my\u001b[23m: 1.0000058477386122}\n",
      "Iteration 25100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000028037665802, \u001b[3my\u001b[23m: 1.0000056187605495}\n",
      "Iteration 25200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000026939805073, \u001b[3my\u001b[23m: 1.000005398748482}\n",
      "Iteration 25300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000025884932706, \u001b[3my\u001b[23m: 1.0000051873513351}\n",
      "Iteration 25400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000024871365434, \u001b[3my\u001b[23m: 1.0000049842317784}\n",
      "Iteration 25500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000023897485912, \u001b[3my\u001b[23m: 1.0000047890656933}\n",
      "Iteration 25600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000022961740118, \u001b[3my\u001b[23m: 1.0000046015416488}\n",
      "Iteration 25700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000002206263488, \u001b[3my\u001b[23m: 1.0000044213604113}\n",
      "Iteration 25800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000021198735485, \u001b[3my\u001b[23m: 1.0000042482344618}\n",
      "Iteration 25900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000020368663403, \u001b[3my\u001b[23m: 1.00000408188754}\n",
      "Iteration 26000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001957109409, \u001b[3my\u001b[23m: 1.000003922054204}\n",
      "Iteration 26100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000018804754847, \u001b[3my\u001b[23m: 1.000003768479404}\n",
      "Iteration 26200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000018068422825, \u001b[3my\u001b[23m: 1.0000036209180783}\n",
      "Iteration 26300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001736092305, \u001b[3my\u001b[23m: 1.0000034791347603}\n",
      "Iteration 26400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000016681126558, \u001b[3my\u001b[23m: 1.0000033429032038}\n",
      "Iteration 26500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001602794859, \u001b[3my\u001b[23m: 1.0000032120060214}\n",
      "Iteration 26600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000015400346853, \u001b[3my\u001b[23m: 1.0000030862343365}\n",
      "Iteration 26700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001479731988, \u001b[3my\u001b[23m: 1.0000029653874531}\n",
      "Iteration 26800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000014217905404, \u001b[3my\u001b[23m: 1.0000028492725317}\n",
      "Iteration 26900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000013661178855, \u001b[3my\u001b[23m: 1.0000027377042875}\n",
      "Iteration 27000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001312625184, \u001b[3my\u001b[23m: 1.0000026305046856}\n",
      "Iteration 27100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000012612270774, \u001b[3my\u001b[23m: 1.0000025275026658}\n",
      "Iteration 27200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000012118415489, \u001b[3my\u001b[23m: 1.0000024285338651}\n",
      "Iteration 27300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000011643897924, \u001b[3my\u001b[23m: 1.0000023334403574}\n",
      "Iteration 27400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000001118796088, \u001b[3my\u001b[23m: 1.000002242070397}\n",
      "Iteration 27500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000010749876813, \u001b[3my\u001b[23m: 1.0000021542781843}\n",
      "Iteration 27600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000010328946665, \u001b[3my\u001b[23m: 1.0000020699236265}\n",
      "Iteration 27700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000009924498734, \u001b[3my\u001b[23m: 1.000001988872115}\n",
      "Iteration 27800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000953588765, \u001b[3my\u001b[23m: 1.0000019109943163}\n",
      "Iteration 27900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000009162493295, \u001b[3my\u001b[23m: 1.000001836165958}\n",
      "Iteration 28000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000880371983, \u001b[3my\u001b[23m: 1.000001764267634}\n",
      "Iteration 28100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000008458994742, \u001b[3my\u001b[23m: 1.0000016951846118}\n",
      "Iteration 28200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000812776795, \u001b[3my\u001b[23m: 1.000001628806655}\n",
      "Iteration 28300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000007809510907, \u001b[3my\u001b[23m: 1.0000015650278424}\n",
      "Iteration 28400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000750371577, \u001b[3my\u001b[23m: 1.0000015037464014}\n",
      "Iteration 28500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000007209894568, \u001b[3my\u001b[23m: 1.0000014448645422}\n",
      "Iteration 28600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000006927578438, \u001b[3my\u001b[23m: 1.0000013882883048}\n",
      "Iteration 28700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000006656316878, \u001b[3my\u001b[23m: 1.000001333927408}\n",
      "Iteration 28800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000006395677032, \u001b[3my\u001b[23m: 1.0000012816951076}\n",
      "Iteration 28900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000006145242992, \u001b[3my\u001b[23m: 1.0000012315080542}\n",
      "Iteration 29000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000590461513, \u001b[3my\u001b[23m: 1.0000011832861633}\n",
      "Iteration 29100. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000567340947, \u001b[3my\u001b[23m: 1.000001136952486}\n",
      "Iteration 29200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000545125707, \u001b[3my\u001b[23m: 1.0000010924330842}\n",
      "Iteration 29300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000005237803427, \u001b[3my\u001b[23m: 1.0000010496569174}\n",
      "Iteration 29400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000005032707937, \u001b[3my\u001b[23m: 1.0000010085557274}\n",
      "Iteration 29500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000004835643317, \u001b[3my\u001b[23m: 1.0000009690639269}\n",
      "Iteration 29600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000004646295106, \u001b[3my\u001b[23m: 1.0000009311184972}\n",
      "Iteration 29700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000004464361152, \u001b[3my\u001b[23m: 1.0000008946588872}\n",
      "Iteration 29800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000428955115, \u001b[3my\u001b[23m: 1.0000008596269199}\n",
      "Iteration 29900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000004121586141, \u001b[3my\u001b[23m: 1.000000825966691}\n",
      "Iteration 30000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000003960198094, \u001b[3my\u001b[23m: 1.0000007936244872}\n",
      "Iteration 30100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000003805129474, \u001b[3my\u001b[23m: 1.0000007625486993}\n",
      "Iteration 30200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000365613285, \u001b[3my\u001b[23m: 1.0000007326897404}\n",
      "Iteration 30300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000003512970441, \u001b[3my\u001b[23m: 1.000000703999961}\n",
      "Iteration 30400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000003375413813, \u001b[3my\u001b[23m: 1.0000006764335814}\n",
      "Iteration 30500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000003243243454, \u001b[3my\u001b[23m: 1.0000006499466114}\n",
      "Iteration 30600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000311624846, \u001b[3my\u001b[23m: 1.0000006244967858}\n",
      "Iteration 30700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002994226176, \u001b[3my\u001b[23m: 1.0000006000434936}\n",
      "Iteration 30800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002876981893, \u001b[3my\u001b[23m: 1.0000005765477136}\n",
      "Iteration 30900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002764328517, \u001b[3my\u001b[23m: 1.0000005539719528}\n",
      "Iteration 31000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002656086284, \u001b[3my\u001b[23m: 1.0000005322801861}\n",
      "Iteration 31100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002552082468, \u001b[3my\u001b[23m: 1.0000005114377994}\n",
      "Iteration 31200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002452151107, \u001b[3my\u001b[23m: 1.000000491411534}\n",
      "Iteration 31300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002356132738, \u001b[3my\u001b[23m: 1.0000004721694324}\n",
      "Iteration 31400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002263874141, \u001b[3my\u001b[23m: 1.000000453680791}\n",
      "Iteration 31500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002175228095, \u001b[3my\u001b[23m: 1.000000435916105}\n",
      "Iteration 31600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002090053137, \u001b[3my\u001b[23m: 1.0000004188470262}\n",
      "Iteration 31700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000002008213356, \u001b[3my\u001b[23m: 1.0000004024463176}\n",
      "Iteration 31800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001929578157, \u001b[3my\u001b[23m: 1.000000386687808}\n",
      "Iteration 31900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001854022065, \u001b[3my\u001b[23m: 1.0000003715463521}\n",
      "Iteration 32000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001781424503, \u001b[3my\u001b[23m: 1.0000003569977867}\n",
      "Iteration 32100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001711669624, \u001b[3my\u001b[23m: 1.0000003430188953}\n",
      "Iteration 32200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000164464613, \u001b[3my\u001b[23m: 1.0000003295873743}\n",
      "Iteration 32300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001580247055, \u001b[3my\u001b[23m: 1.0000003166817875}\n",
      "Iteration 32400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001518369643, \u001b[3my\u001b[23m: 1.0000003042815422}\n",
      "Iteration 32500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001458915158, \u001b[3my\u001b[23m: 1.000000292366852}\n",
      "Iteration 32600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001401788714, \u001b[3my\u001b[23m: 1.000000280918702}\n",
      "Iteration 32700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001346899154, \u001b[3my\u001b[23m: 1.0000002699188242}\n",
      "Iteration 32800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001294158898, \u001b[3my\u001b[23m: 1.0000002593496664}\n",
      "Iteration 32900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001243483774, \u001b[3my\u001b[23m: 1.0000002491943623}\n",
      "Iteration 33000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000119479293, \u001b[3my\u001b[23m: 1.000000239436708}\n",
      "Iteration 33100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001148008661, \u001b[3my\u001b[23m: 1.0000002300611324}\n",
      "Iteration 33200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001103056317, \u001b[3my\u001b[23m: 1.0000002210526746}\n",
      "Iteration 33300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000105986416, \u001b[3my\u001b[23m: 1.0000002123969585}\n",
      "Iteration 33400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000001018363274, \u001b[3my\u001b[23m: 1.0000002040801732}\n",
      "Iteration 33500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000097848743, \u001b[3my\u001b[23m: 1.0000001960890472}\n",
      "Iteration 33600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000940172997, \u001b[3my\u001b[23m: 1.0000001884108278}\n",
      "Iteration 33700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000903358837, \u001b[3my\u001b[23m: 1.0000001810332635}\n",
      "Iteration 33800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000867986194, \u001b[3my\u001b[23m: 1.0000001739445796}\n",
      "Iteration 33900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000833998632, \u001b[3my\u001b[23m: 1.0000001671334662}\n",
      "Iteration 34000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000801341915, \u001b[3my\u001b[23m: 1.000000160589054}\n",
      "Iteration 34100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000769963928, \u001b[3my\u001b[23m: 1.0000001543009003}\n",
      "Iteration 34200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000739814605, \u001b[3my\u001b[23m: 1.0000001482589707}\n",
      "Iteration 34300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000071084583, \u001b[3my\u001b[23m: 1.0000001424536231}\n",
      "Iteration 34400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000068301138, \u001b[3my\u001b[23m: 1.0000001368755942}\n",
      "Iteration 34500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000656266843, \u001b[3my\u001b[23m: 1.0000001315159845}\n",
      "Iteration 34600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000063056953, \u001b[3my\u001b[23m: 1.0000001263662388}\n",
      "Iteration 34700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000605878443, \u001b[3my\u001b[23m: 1.0000001214181407}\n",
      "Iteration 34800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000582154187, \u001b[3my\u001b[23m: 1.0000001166637955}\n",
      "Iteration 34900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000055935889, \u001b[3my\u001b[23m: 1.0000001120956143}\n",
      "Iteration 35000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000537456188, \u001b[3my\u001b[23m: 1.0000001077063088}\n",
      "Iteration 35100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000516411123, \u001b[3my\u001b[23m: 1.0000001034888744}\n",
      "Iteration 35200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000496190116, \u001b[3my\u001b[23m: 1.000000099436581}\n",
      "Iteration 35300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000476760897, \u001b[3my\u001b[23m: 1.0000000955429624}\n",
      "Iteration 35400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000458092464, \u001b[3my\u001b[23m: 1.0000000918018048}\n",
      "Iteration 35500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000440155028, \u001b[3my\u001b[23m: 1.00000008820714}\n",
      "Iteration 35600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000422919963, \u001b[3my\u001b[23m: 1.00000008475323}\n",
      "Iteration 35700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000040635977, \u001b[3my\u001b[23m: 1.0000000814345642}\n",
      "Iteration 35800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000039044802, \u001b[3my\u001b[23m: 1.0000000782458471}\n",
      "Iteration 35900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000375159321, \u001b[3my\u001b[23m: 1.0000000751819895}\n",
      "Iteration 36000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000036046928, \u001b[3my\u001b[23m: 1.0000000722381026}\n",
      "Iteration 36100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000346354458, \u001b[3my\u001b[23m: 1.0000000694094902}\n",
      "Iteration 36200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000332792323, \u001b[3my\u001b[23m: 1.0000000666916355}\n",
      "Iteration 36300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000319761242, \u001b[3my\u001b[23m: 1.0000000640802054}\n",
      "Iteration 36400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000307240415, \u001b[3my\u001b[23m: 1.0000000615710292}\n",
      "Iteration 36500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000295209857, \u001b[3my\u001b[23m: 1.0000000591601035}\n",
      "Iteration 36600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000283650383, \u001b[3my\u001b[23m: 1.0000000568435827}\n",
      "Iteration 36700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000027254354, \u001b[3my\u001b[23m: 1.0000000546177696}\n",
      "Iteration 36800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000261871598, \u001b[3my\u001b[23m: 1.0000000524791108}\n",
      "Iteration 36900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000251617545, \u001b[3my\u001b[23m: 1.0000000504241966}\n",
      "Iteration 37000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000024176501, \u001b[3my\u001b[23m: 1.0000000484497473}\n",
      "Iteration 37100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000232298265, \u001b[3my\u001b[23m: 1.0000000465526098}\n",
      "Iteration 37200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000223202197, \u001b[3my\u001b[23m: 1.0000000447297563}\n",
      "Iteration 37300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000214462308, \u001b[3my\u001b[23m: 1.0000000429782812}\n",
      "Iteration 37400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000206064645, \u001b[3my\u001b[23m: 1.0000000412953882}\n",
      "Iteration 37500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000197995818, \u001b[3my\u001b[23m: 1.0000000396783935}\n",
      "Iteration 37600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000190242935, \u001b[3my\u001b[23m: 1.000000038124715}\n",
      "Iteration 37700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000018279363, \u001b[3my\u001b[23m: 1.000000036631873}\n",
      "Iteration 37800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000175636015, \u001b[3my\u001b[23m: 1.0000000351974856}\n",
      "Iteration 37900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000016875866, \u001b[3my\u001b[23m: 1.000000033819263}\n",
      "Iteration 38000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000162150595, \u001b[3my\u001b[23m: 1.0000000324950056}\n",
      "Iteration 38100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000155801296, \u001b[3my\u001b[23m: 1.0000000312226047}\n",
      "Iteration 38200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000149700614, \u001b[3my\u001b[23m: 1.0000000300000271}\n",
      "Iteration 38300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000143838819, \u001b[3my\u001b[23m: 1.0000000288253226}\n",
      "Iteration 38400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000013820654, \u001b[3my\u001b[23m: 1.0000000276966128}\n",
      "Iteration 38500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000013279482, \u001b[3my\u001b[23m: 1.000000026612103}\n",
      "Iteration 38600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000127595008, \u001b[3my\u001b[23m: 1.00000002557006}\n",
      "Iteration 38700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000122598802, \u001b[3my\u001b[23m: 1.0000000245688196}\n",
      "Iteration 38800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000117798233, \u001b[3my\u001b[23m: 1.000000023606785}\n",
      "Iteration 38900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000113185632, \u001b[3my\u001b[23m: 1.0000000226824188}\n",
      "Iteration 39000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000108753646, \u001b[3my\u001b[23m: 1.0000000217942482}\n",
      "Iteration 39100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000104495201, \u001b[3my\u001b[23m: 1.0000000209408553}\n",
      "Iteration 39200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000100403503, \u001b[3my\u001b[23m: 1.000000020120878}\n",
      "Iteration 39300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000096472017, \u001b[3my\u001b[23m: 1.0000000193330079}\n",
      "Iteration 39400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000009269448, \u001b[3my\u001b[23m: 1.0000000185759887}\n",
      "Iteration 39500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000089064858, \u001b[3my\u001b[23m: 1.000000017848612}\n",
      "Iteration 39600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000085577356, \u001b[3my\u001b[23m: 1.000000017149716}\n",
      "Iteration 39700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000008222642, \u001b[3my\u001b[23m: 1.0000000164781875}\n",
      "Iteration 39800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000079006686, \u001b[3my\u001b[23m: 1.0000000158329527}\n",
      "Iteration 39900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000075913031, \u001b[3my\u001b[23m: 1.0000000152129838}\n",
      "Iteration 40000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000072940511, \u001b[3my\u001b[23m: 1.0000000146172903}\n",
      "Iteration 40100. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000007008439, \u001b[3my\u001b[23m: 1.0000000140449228}\n",
      "Iteration 40200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000067340096, \u001b[3my\u001b[23m: 1.0000000134949663}\n",
      "Iteration 40300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000064703263, \u001b[3my\u001b[23m: 1.0000000129665443}\n",
      "Iteration 40400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000006216968, \u001b[3my\u001b[23m: 1.0000000124588138}\n",
      "Iteration 40500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000005973531, \u001b[3my\u001b[23m: 1.0000000119709656}\n",
      "Iteration 40600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000005739627, \u001b[3my\u001b[23m: 1.0000000115022216}\n",
      "Iteration 40700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000055148817, \u001b[3my\u001b[23m: 1.000000011051832}\n",
      "Iteration 40800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000052989366, \u001b[3my\u001b[23m: 1.0000000106190774}\n",
      "Iteration 40900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000050914482, \u001b[3my\u001b[23m: 1.0000000102032702}\n",
      "Iteration 41000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000048920838, \u001b[3my\u001b[23m: 1.0000000098037436}\n",
      "Iteration 41100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000047005262, \u001b[3my\u001b[23m: 1.000000009419862}\n",
      "Iteration 41200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000004516469, \u001b[3my\u001b[23m: 1.000000009051011}\n",
      "Iteration 41300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000043396187, \u001b[3my\u001b[23m: 1.0000000086966025}\n",
      "Iteration 41400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000041696928, \u001b[3my\u001b[23m: 1.0000000083560707}\n",
      "Iteration 41500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000004006421, \u001b[3my\u001b[23m: 1.000000008028874}\n",
      "Iteration 41600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000038495425, \u001b[3my\u001b[23m: 1.0000000077144895}\n",
      "Iteration 41700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000036988075, \u001b[3my\u001b[23m: 1.0000000074124162}\n",
      "Iteration 41800. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000003553975, \u001b[3my\u001b[23m: 1.000000007122171}\n",
      "Iteration 41900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000003414813, \u001b[3my\u001b[23m: 1.000000006843291}\n",
      "Iteration 42000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000032811, \u001b[3my\u001b[23m: 1.0000000065753298}\n",
      "Iteration 42100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000031526222, \u001b[3my\u001b[23m: 1.00000000631786}\n",
      "Iteration 42200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000030291758, \u001b[3my\u001b[23m: 1.0000000060704735}\n",
      "Iteration 42300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000029105636, \u001b[3my\u001b[23m: 1.000000005832774}\n",
      "Iteration 42400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000027965956, \u001b[3my\u001b[23m: 1.0000000056043818}\n",
      "Iteration 42500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000026870886, \u001b[3my\u001b[23m: 1.0000000053849298}\n",
      "Iteration 42600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000002581871, \u001b[3my\u001b[23m: 1.0000000051740734}\n",
      "Iteration 42700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000002480773, \u001b[3my\u001b[23m: 1.000000004971473}\n",
      "Iteration 42800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000023836346, \u001b[3my\u001b[23m: 1.0000000047768074}\n",
      "Iteration 42900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000002290299, \u001b[3my\u001b[23m: 1.0000000045897632}\n",
      "Iteration 43000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000022006184, \u001b[3my\u001b[23m: 1.000000004410043}\n",
      "Iteration 43100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000021144495, \u001b[3my\u001b[23m: 1.00000000423736}\n",
      "Iteration 43200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000020316546, \u001b[3my\u001b[23m: 1.0000000040714392}\n",
      "Iteration 43300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000019521014, \u001b[3my\u001b[23m: 1.0000000039120145}\n",
      "Iteration 43400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000018756636, \u001b[3my\u001b[23m: 1.0000000037588328}\n",
      "Iteration 43500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000018022184, \u001b[3my\u001b[23m: 1.0000000036116485}\n",
      "Iteration 43600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000017316488, \u001b[3my\u001b[23m: 1.0000000034702272}\n",
      "Iteration 43700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000016638428, \u001b[3my\u001b[23m: 1.0000000033343435}\n",
      "Iteration 43800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000015986916, \u001b[3my\u001b[23m: 1.0000000032037806}\n",
      "Iteration 43900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000001536092, \u001b[3my\u001b[23m: 1.0000000030783307}\n",
      "Iteration 44000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000001475944, \u001b[3my\u001b[23m: 1.000000002957794}\n",
      "Iteration 44100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000014181505, \u001b[3my\u001b[23m: 1.0000000028419755}\n",
      "Iteration 44200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000001362621, \u001b[3my\u001b[23m: 1.0000000027306943}\n",
      "Iteration 44300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000013092645, \u001b[3my\u001b[23m: 1.000000002623768}\n",
      "Iteration 44400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000012579977, \u001b[3my\u001b[23m: 1.0000000025210296}\n",
      "Iteration 44500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000012087382, \u001b[3my\u001b[23m: 1.0000000024223135}\n",
      "Iteration 44600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000011614076, \u001b[3my\u001b[23m: 1.000000002327463}\n",
      "Iteration 44700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000011159302, \u001b[3my\u001b[23m: 1.000000002236326}\n",
      "Iteration 44800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000010722345, \u001b[3my\u001b[23m: 1.0000000021487594}\n",
      "Iteration 44900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000010302492, \u001b[3my\u001b[23m: 1.000000002064621}\n",
      "Iteration 45000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000989908, \u001b[3my\u001b[23m: 1.0000000019837771}\n",
      "Iteration 45100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000009511467, \u001b[3my\u001b[23m: 1.0000000019060993}\n",
      "Iteration 45200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000009139027, \u001b[3my\u001b[23m: 1.0000000018314623}\n",
      "Iteration 45300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000008781174, \u001b[3my\u001b[23m: 1.0000000017597488}\n",
      "Iteration 45400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000008437333, \u001b[3my\u001b[23m: 1.000000001690843}\n",
      "Iteration 45500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000008106955, \u001b[3my\u001b[23m: 1.0000000016246353}\n",
      "Iteration 45600. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000778951, \u001b[3my\u001b[23m: 1.000000001561019}\n",
      "Iteration 45700. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000000074845, \u001b[3my\u001b[23m: 1.0000000014998947}\n",
      "Iteration 45800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000007191427, \u001b[3my\u001b[23m: 1.000000001441163}\n",
      "Iteration 45900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000006909833, \u001b[3my\u001b[23m: 1.0000000013847314}\n",
      "Iteration 46000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000663926, \u001b[3my\u001b[23m: 1.0000000013305088}\n",
      "Iteration 46100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000006379288, \u001b[3my\u001b[23m: 1.0000000012784105}\n",
      "Iteration 46200. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000000061295, \u001b[3my\u001b[23m: 1.0000000012283525}\n",
      "Iteration 46300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000005889487, \u001b[3my\u001b[23m: 1.0000000011802541}\n",
      "Iteration 46400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000005658871, \u001b[3my\u001b[23m: 1.0000000011340386}\n",
      "Iteration 46500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000005437284, \u001b[3my\u001b[23m: 1.0000000010896326}\n",
      "Iteration 46600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000005224379, \u001b[3my\u001b[23m: 1.0000000010469665}\n",
      "Iteration 46700. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000501981, \u001b[3my\u001b[23m: 1.0000000010059706}\n",
      "Iteration 46800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000004823246, \u001b[3my\u001b[23m: 1.0000000009665795}\n",
      "Iteration 46900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000004634384, \u001b[3my\u001b[23m: 1.0000000009287313}\n",
      "Iteration 47000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000004452916, \u001b[3my\u001b[23m: 1.0000000008923653}\n",
      "Iteration 47100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000004278546, \u001b[3my\u001b[23m: 1.0000000008574217}\n",
      "Iteration 47200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000411101, \u001b[3my\u001b[23m: 1.000000000823847}\n",
      "Iteration 47300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003950036, \u001b[3my\u001b[23m: 1.000000000791588}\n",
      "Iteration 47400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003795366, \u001b[3my\u001b[23m: 1.000000000760592}\n",
      "Iteration 47500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003646747, \u001b[3my\u001b[23m: 1.0000000007308085}\n",
      "Iteration 47600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003503942, \u001b[3my\u001b[23m: 1.0000000007021903}\n",
      "Iteration 47700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003366734, \u001b[3my\u001b[23m: 1.000000000674694}\n",
      "Iteration 47800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000003234906, \u001b[3my\u001b[23m: 1.0000000006482757}\n",
      "Iteration 47900. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000310823, \u001b[3my\u001b[23m: 1.0000000006228897}\n",
      "Iteration 48000. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000298652, \u001b[3my\u001b[23m: 1.000000000598499}\n",
      "Iteration 48100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002869576, \u001b[3my\u001b[23m: 1.000000000575063}\n",
      "Iteration 48200. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002757212, \u001b[3my\u001b[23m: 1.0000000005525458}\n",
      "Iteration 48300. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000264925, \u001b[3my\u001b[23m: 1.0000000005309098}\n",
      "Iteration 48400. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002545513, \u001b[3my\u001b[23m: 1.000000000510121}\n",
      "Iteration 48500. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000244584, \u001b[3my\u001b[23m: 1.0000000004901466}\n",
      "Iteration 48600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002350073, \u001b[3my\u001b[23m: 1.000000000470955}\n",
      "Iteration 48700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002258052, \u001b[3my\u001b[23m: 1.000000000452514}\n",
      "Iteration 48800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002169633, \u001b[3my\u001b[23m: 1.000000000434795}\n",
      "Iteration 48900. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002084684, \u001b[3my\u001b[23m: 1.0000000004177707}\n",
      "Iteration 49000. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000002003058, \u001b[3my\u001b[23m: 1.0000000004014131}\n",
      "Iteration 49100. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001924623, \u001b[3my\u001b[23m: 1.0000000003856946}\n",
      "Iteration 49200. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000184926, \u001b[3my\u001b[23m: 1.0000000003705922}\n",
      "Iteration 49300. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001776843, \u001b[3my\u001b[23m: 1.0000000003560794}\n",
      "Iteration 49400. Current min estimate: {\u001b[3mx\u001b[23m: 1.000000000170727, \u001b[3my\u001b[23m: 1.000000000342137}\n",
      "Iteration 49500. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001640417, \u001b[3my\u001b[23m: 1.0000000003287397}\n",
      "Iteration 49600. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001576184, \u001b[3my\u001b[23m: 1.0000000003158678}\n",
      "Iteration 49700. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001514469, \u001b[3my\u001b[23m: 1.0000000003035}\n",
      "Iteration 49800. Current min estimate: {\u001b[3mx\u001b[23m: 1.0000000001455172, \u001b[3my\u001b[23m: 1.0000000002916167}\n",
      "Iteration 49900. Current min estimate: {\u001b[3mx\u001b[23m: 1.00000000013982, \u001b[3my\u001b[23m: 1.0000000002801994}\n",
      "\n",
      "Results:\n",
      "--- Min Value: -1.4210854715202004e-14\n",
      "--- Min Location: {\u001b[3mx\u001b[23m: 1.000000000134399, \u001b[3my\u001b[23m: 1.0000000002693354}\n"
     ]
    }
   ],
   "source": [
    "x = gradient_descent.Variable(\"x\")\n",
    "y = gradient_descent.Variable(\"y\")\n",
    "f = gradient_descent.MultiVariableFunction(                                                    # f(x, y) =\n",
    "    variables={x, y},\n",
    "    expressions=[\n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=100, exponent=4),        # 100x^4 -\n",
    "        gradient_descent.Multiply(                                                             # 200x^2y +\n",
    "            a=gradient_descent.PolynomialExpression(variable=x, coefficient=-200, exponent=2),\n",
    "            b=gradient_descent.PolynomialExpression(variable=y, coefficient=1, exponent=1),\n",
    "        ),  \n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=1, exponent=2),          # x^2 -\n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=-2, exponent=1),         # 2x +\n",
    "        gradient_descent.PolynomialExpression(variable=y, coefficient=100, exponent=2),        # 100y^2 +\n",
    "        gradient_descent.ConstantExpression(real=1.0),                                         # 1\n",
    "    ],\n",
    ")\n",
    "\n",
    "f.gradient()\n",
    "\n",
    "# The grad descent process on this function is quite sensitive to initial point. \n",
    "# If started too far away from minima, the gradients 'explode' and convergence does not occur.\n",
    "initial_points = [\n",
    "    {x: 1, y: 1},\n",
    "    {x: 1.1, y: 1.1},\n",
    "#     {x: -1.5, y: -1.5},\n",
    "]\n",
    "\n",
    "for i_p in initial_points:\n",
    "    minimum_val, minimum_point = gradient_descent.gradient_descent(\n",
    "        gamma=0.001,\n",
    "        max_iterations=50000,\n",
    "        initial_point=i_p,\n",
    "        f=f,\n",
    "    )\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"--- Min Value: {minimum_val}\")\n",
    "    print(f\"--- Min Location: {minimum_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Changing initial starting points\n",
    "\n",
    "TODO - function with two local minima and one global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(x, y) = x^4 + y^4 - 4xy + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration as not changed value. Stopping early.\n",
      "\n",
      "Results:\n",
      "--- Min Value: -1.0\n",
      "--- Min Location: {\u001b[3mx\u001b[23m: 1.0, \u001b[3my\u001b[23m: 1.0}\n",
      "Iteration as not changed value. Stopping early.\n",
      "\n",
      "Results:\n",
      "--- Min Value: -1.0\n",
      "--- Min Location: {\u001b[3mx\u001b[23m: -1.0, \u001b[3my\u001b[23m: -1.0}\n",
      "Iteration 0. Current min estimate: {\u001b[3mx\u001b[23m: -0.75, \u001b[3my\u001b[23m: -0.75}\n",
      "Iteration as not changed value. Stopping early.\n",
      "\n",
      "Results:\n",
      "--- Min Value: -1.0\n",
      "--- Min Location: {\u001b[3mx\u001b[23m: -1.0, \u001b[3my\u001b[23m: -1.0}\n"
     ]
    }
   ],
   "source": [
    "x = gradient_descent.Variable(\"x\")\n",
    "y = gradient_descent.Variable(\"y\")\n",
    "f = gradient_descent.MultiVariableFunction(                                                    # f(x, y) =\n",
    "    variables={x, y},\n",
    "    expressions=[\n",
    "        gradient_descent.PolynomialExpression(variable=x, coefficient=1, exponent=4),          # x^4 +\n",
    "        gradient_descent.PolynomialExpression(variable=y, coefficient=1, exponent=4),          # y^4 -\n",
    "        gradient_descent.Multiply(                                                             # 4xy +\n",
    "            a=gradient_descent.PolynomialExpression(variable=x, coefficient=-4, exponent=1),\n",
    "            b=gradient_descent.PolynomialExpression(variable=y, coefficient=1, exponent=1),\n",
    "        ),  \n",
    "        gradient_descent.ConstantExpression(real=1.0),                                         # 1\n",
    "    ],\n",
    ")\n",
    "\n",
    "# The grad descent process on this function is quite sensitive to initial point. \n",
    "# If started too far away from minima, the gradients 'explode' and convergence does not occur.\n",
    "initial_points = [\n",
    "    {x: 1, y: 1},\n",
    "    {x: -1, y: -1},\n",
    "    {x: -1.5, y: -1.5},\n",
    "]\n",
    "\n",
    "for i_p in initial_points:\n",
    "    minimum_val, minimum_point = gradient_descent.gradient_descent(\n",
    "        gamma=0.1,\n",
    "        max_iterations=50000,\n",
    "        initial_point=i_p,\n",
    "        f=f,\n",
    "    )\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"--- Min Value: {minimum_val}\")\n",
    "    print(f\"--- Min Location: {minimum_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "*  RUMELHART, David E.; HINTON, Geoffrey E.; WILLIAMS, Ronald J. (1986). \"Learning representations by back-propagating errors\". Nature. 323 (6088): 533–536. doi:10.1038/323533a0. S2CID 205001834 -http://www.cs.utoronto.ca/~hinton/absps/naturebp.pdf\n",
    "* STEWART, J. (2019). \"Calculus: concepts and contexts\". Boston, MA, USA, Cengage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "The full `gradient_descent` implementation is available online at [github.com/thundergolfer/modelling_change/](https://github.com/thundergolfer/modelling_change/), but it has also been copied in below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO copy implementation of `gradient_descent`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
